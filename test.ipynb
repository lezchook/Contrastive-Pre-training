{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from utils import get_data, get_batches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"tom-010/google_natural_questions_answerability\"\n",
    "DEVICE = \"cpu\"\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "train_data = [{\"question\": q, \"context\": c} for q, c in zip(dataset[\"train\"]['question'], dataset[\"train\"][\"answer\"]) if c is not None]\n",
    "valid_data = [{\"question\": q, \"context\": c} for q, c in zip(dataset[\"validation\"]['question'], dataset[\"validation\"][\"answer\"]) if c is not None]\n",
    "\n",
    "with open(\"filtered_array.txt\", \"r\") as f:\n",
    "    filtered = list(map(int, f.read().split()))\n",
    "    \n",
    "indices = set(range(len(train_data))) - set(filtered)\n",
    "queries_train, passages_train = get_data(indices, train_data)\n",
    "\n",
    "with open(\"filtered_array_val.txt\", \"r\") as f:\n",
    "    filtered = list(map(int, f.read().split()))\n",
    "    \n",
    "indices = set(range(len(valid_data))) - set(filtered)\n",
    "queries_valid, passages_valid = get_data(indices, valid_data)\n",
    "\n",
    "train_data_batched = get_batches(queries_train, passages_train, BATCH_SIZE)\n",
    "valid_data_batched = get_batches(queries_valid, passages_valid, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg(scores, labels):\n",
    "    sorted_indices = torch.argsort(scores, descending=True)\n",
    "    sorted_labels = labels[sorted_indices]\n",
    "\n",
    "    dcg = sum((sorted_labels[i].item() / np.log2(i + 2)) for i in range(len(sorted_labels)))\n",
    "    idcg = sum((1 / np.log2(i + 2)) for i in range(sum(labels).int().item()))\n",
    "\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./2_tokenizer_rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"./2_new_rubert-tiny2\").to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_scores = []\n",
    "progressBar = tqdm(range(len(valid_data_batched)))\n",
    "\n",
    "for batch in valid_data_batched:\n",
    "    \n",
    "    query = tokenizer(batch[\"question\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    passage = tokenizer(batch[\"context\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_emb = model(**query).last_hidden_state.mean(dim=1)\n",
    "        passage_emb = model(**passage).last_hidden_state.mean(dim=1)\n",
    "    \n",
    "\n",
    "    scores = torch.zeros(len(query_emb), len(passage_emb))\n",
    "    for i in range(len(query_emb)):\n",
    "        scores[i] = F.cosine_similarity(query_emb[i].unsqueeze(0), passage_emb)\n",
    "\n",
    "    for i in range(len(batch[\"question\"])):\n",
    "        labels = torch.zeros(len(batch[\"context\"]))\n",
    "        labels[i] = 1\n",
    "        ndcg_scores.append(get_ndcg(scores[i], labels))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    progressBar.update(1)\n",
    "\n",
    "print(np.mean(ndcg_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
