{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from utils import get_data, get_batches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"sberquad\"\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer_rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"./new_rubert-tiny2\").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "queries, passages = get_data(range(len(test_data)), test_data)\n",
    "test_data_batched = get_batches(queries, passages, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg(scores, labels):\n",
    "    sorted_indices = torch.argsort(scores, descending=True)\n",
    "    sorted_labels = labels[sorted_indices]\n",
    "\n",
    "    dcg = sum((sorted_labels[i].item() / np.log2(i + 2)) for i in range(len(sorted_labels)))\n",
    "    idcg = sum((1 / np.log2(i + 2)) for i in range(sum(labels).int().item()))\n",
    "\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_scores = []\n",
    "progressBar = tqdm(range(len(test_data_batched)))\n",
    "\n",
    "for batch in test_data_batched:\n",
    "    \n",
    "    query = tokenizer(batch[\"question\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    passage = tokenizer(batch[\"context\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_emb = model(**query).last_hidden_state.mean(dim=1)\n",
    "        passage_emb = model(**passage).last_hidden_state.mean(dim=1)\n",
    "    \n",
    "\n",
    "    scores = torch.zeros(len(query_emb), len(passage_emb))\n",
    "    for i in range(len(query_emb)):\n",
    "        scores[i] = F.cosine_similarity(query_emb[i].unsqueeze(0), passage_emb)\n",
    "\n",
    "    for i in range(len(batch[\"question\"])):\n",
    "        labels = torch.zeros(len(batch[\"context\"]))\n",
    "        labels[i] = 1\n",
    "        ndcg_scores.append(get_ndcg(scores[i], labels))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    progressBar.update(1)\n",
    "\n",
    "print(np.mean(ndcg_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
