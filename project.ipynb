{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"cointegrated/rubert-tiny2\"\n",
    "DATASET_NAME = \"sberquad\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "\n",
    "    def forward(self, query, passage, negative_passages, temperature):\n",
    "        s_positive = F.cosine_similarity(query, passage, dim=-1) / temperature\n",
    "        s_negative = F.cosine_similarity(query.unsqueeze(1), negative_passages, dim=-1) / temperature\n",
    "\n",
    "        exp_for_sum = torch.cat([s_positive.unsqueeze(-1), s_negative], dim=-1)\n",
    "        log_exp_sum = torch.logsumexp(exp_for_sum, dim=-1)\n",
    "        \n",
    "        return (-s_positive + log_exp_sum).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loss_function = ContrastiveLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "total_steps = len(trainloader) * NUM_EPOCHS\n",
    "num_warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f527fb48e7a14be988366a8729815a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.20657781182015442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53179fe2bc54464d8ec23ea280066f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.08865785632417937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d35554c967f4d97b5aaa3c9d188016b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.04058851027631776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e1a4ea80ed45589770fbf04014b3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.028545971014370904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408f4233a9794fe49738c9bd102b80cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.020955271911082485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d0f05b0f984815be4dc58f301398b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.015354634593663348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131872eaa8ac45d8a5412f98e0d4a86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.012018820105868097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d523cafaa44e4d03b25a6304d551c964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.009085472926965587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9378912d734dc087ede16542ee6d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.006801100278801183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85e1b561fe547bdb38541e1f6ee6926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/2833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0061528688599774665\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    progressBar = tqdm(range(len(trainloader)), desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in trainloader:\n",
    "        query = tokenizer(batch[\"question\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "        passage = tokenizer(batch[\"context\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "\n",
    "        query_emb = model(**query).last_hidden_state.mean(dim=1)\n",
    "        passage_emb = model(**passage).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        negative_passages = []\n",
    "        for i in range(len(passage_emb)):\n",
    "            negatives = torch.cat([passage_emb[:i], passage_emb[i + 1:]])\n",
    "            negative_passages.append(negatives)\n",
    "\n",
    "        negative_passages = torch.stack(negative_passages)\n",
    "\n",
    "        loss = loss_function(query_emb, passage_emb, negative_passages, 0.01)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progressBar.update(1)\n",
    "        total_loss += loss.item()\n",
    "        progressBar.set_postfix({\"Loss\": loss.item()})\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer_rubert-tiny2\\\\tokenizer_config.json',\n",
       " 'tokenizer_rubert-tiny2\\\\special_tokens_map.json',\n",
       " 'tokenizer_rubert-tiny2\\\\vocab.txt',\n",
       " 'tokenizer_rubert-tiny2\\\\added_tokens.json',\n",
       " 'tokenizer_rubert-tiny2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"new_rubert-tiny2\")\n",
    "tokenizer.save_pretrained(\"tokenizer_rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer_rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"new_rubert-tiny2\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd038fbe0b9a420eb08c439fb2c48709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progressBar = tqdm(range(len(train_data)))\n",
    "queries_emb = []\n",
    "passages_emb = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(train_data)):\n",
    "        query = tokenizer(train_data[i][\"question\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "        query_emb = model(**query).last_hidden_state.mean(dim=1)\n",
    "        queries_emb.append(query_emb.cpu())\n",
    "\n",
    "        passage = tokenizer(train_data[i][\"context\"], return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "        passage_emb = model(**passage).last_hidden_state.mean(dim=1)\n",
    "        passages_emb.append(passage_emb.cpu())\n",
    "\n",
    "        progressBar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e9b78139aa497eac0af729407dc0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progressBar = tqdm(range(len(train_data)))\n",
    "number_range = range(0, len(train_data))\n",
    "pool_size = 4000\n",
    "filtered = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    query_emb = queries_emb[i]\n",
    "\n",
    "    top_list = []\n",
    "    pool = random.sample([x for x in number_range if x != i], pool_size)\n",
    "\n",
    "    for j in pool:\n",
    "        passage_emb = passages_emb[j]\n",
    "\n",
    "        cos_sim = F.cosine_similarity(query_emb, passage_emb, dim=-1).item()\n",
    "        top_list.append(cos_sim)\n",
    "\n",
    "    top_list.sort(reverse=True)\n",
    "\n",
    "    passage_emb = passages_emb[i]\n",
    "    cos_sim = F.cosine_similarity(query_emb, passage_emb, dim=-1).item()\n",
    "\n",
    "    if cos_sim < top_list[1]:\n",
    "        filtered.append(i)\n",
    "\n",
    "    progressBar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45328"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered_array.txt\", \"w\") as f:\n",
    "    f.write(\" \".join(map(str, filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
